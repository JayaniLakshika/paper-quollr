# Generated by `rjournal_pdf_article()` using `knitr::purl()`: do not edit by hand
# Please edit paper-quollr.Rmd to modify this file

## ----setup, include=FALSE-----------------------------------------------------
knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE)



## ----load-libraries-----------------------------------------------------------
library(quollr)
library(tibble)
library(knitr)
library(kableExtra)
library(ggplot2)

set.seed(20230531)


## ----echo=FALSE---------------------------------------------------------------
datasets_tb <- tibble(dt = c("s_curve_noise",
                             "s_curve_noise_training", 
                             "s_curve_noise_test", 
                             "s_curve_noise_umap",
                             "s_curve_noise_umap_predict",
                             "s_curve_noise_umap_scaled"), 
                      text = c("Simulated 3D S-curve data with additional four noise dimensions.",
                               "Training data derived from S-curve data.", 
                               "Test data derived from S-curve data.", 
                               "UMAP 2D embedding data of S-curve data (n_neighbors: 15, min_dist: 0.1).",
                               "Predicted UMAP 2D embedding data of S-curve data",
                               "Scaled UMAP 2D embedding data of S-curve data"))


## ----datasets-tb-html, eval=is_html_output(), echo=FALSE----------------------
#> datasets_tb |>
#>   kable(caption = "quollr datasets", col.names = c("data", "explanation"))


## ----datasets-tb-pdf, eval=is_latex_output(), echo=FALSE----------------------
datasets_tb |>
  kable(caption = "quollr datasets", format="latex", col.names = c("data", "explanation"), booktabs = T)  |>
  column_spec(1, width = "4cm") |>
  column_spec(2, width = "8cm")


## -----------------------------------------------------------------------------
scaled_data <- gen_scaled_data(data = s_curve_noise_umap, x = "UMAP1", 
                y = "UMAP2", hex_ratio = NA)
glimpse(scaled_data)


## -----------------------------------------------------------------------------
fit_highd_model(training_data = s_curve_noise_training, x = "UMAP1", y = "UMAP2",
nldr_df_with_id = s_curve_noise_umap_scaled, col_start_2d = "UMAP", col_start_highd = "x")


## ----echo=FALSE---------------------------------------------------------------
lg_vis_tb <- tibble(dt = c(".data", 
                           "benchmark_value", 
                           "triangular_object", 
                           "distance_col"), 
                    text = c("The data frame containing the edge information.",
                             "The threshold value to determine long edges.", 
                             "The triangular object containing the mesh information.", 
                             "The column name in `.data` representing the distances."))


## ----lgvis-tb-html, eval=is_html_output(), echo=FALSE-------------------------
#> lg_vis_tb |>
#>   kable(caption = "The main arguments for `vis_lg_mesh()` and `vis_rmlg_mesh()`", col.names = c("argument", "explanation"))


## ----lgvis-tb-pdf, eval=is_latex_output(), echo=FALSE-------------------------
lg_vis_tb |>
  kable(caption = "The main arguments for `vis\\_lg\\_mesh()` and `vis\\_rmlg\\_mesh()`", format="latex", col.names = c("argument", "explanation"), booktabs = T)  |>
  column_spec(1, width = "4cm") |>
  column_spec(2, width = "8cm")


## ----echo=FALSE---------------------------------------------------------------
dyn_vis_tb <- tibble(dt = c("df", 
                            "df_b", 
                            "df_b_with_center_data", 
                            "benchmark_value",
                            "distance_df",
                            "distance_col",
                            "use_default_benchmark_val",
                            "column_start_text"), 
                     text = c("A data frame containing the high-dimensional data.",
                              "A data frame containing the high-dimensional coordinates of bin centroids/means.",
                              "The dataset with hexbin centroids/ means.", 
                              "The benchmark value used to remove long edges (optional).", 
                              "The distance dataframe.",
                              "The name of the distance column.",
                              "Logical, indicating whether to use default benchmark value  to remove long edges(default is FALSE).",
                              "The text that begin the column name of the high-dimensional data."))


## ----dyvis-tb-html, eval=is_html_output(), echo=FALSE-------------------------
#> dyn_vis_tb |>
#>   kable(caption = "The main arguments for `show_langevitour()`", col.names = c("argument", "explanation"))


## ----dyvis-tb-pdf, eval=is_latex_output(), echo=FALSE-------------------------
dyn_vis_tb |>
  kable(caption = "The main arguments for `show\\_langevitour()`", format="latex", col.names = c("argument", "explanation"), booktabs = T)  |>
  column_spec(1, width = "4cm") |>
  column_spec(2, width = "8cm")


## ----echo=FALSE---------------------------------------------------------------
compute_weights <- function(nldr_df_with_hex_id) {

  ## To get the 2D embeddings average of each bin
  bin_val_hexagons <- nldr_df_with_hex_id |>
    dplyr::group_by(hb_id) |>
    dplyr::summarise(dplyr::across(tidyselect::everything(), mean))

  ## Rename columns of averaged 2D embeddings
  names(bin_val_hexagons) <- c("hb_id", paste0("avg_", tolower(names(nldr_df_with_hex_id)[1:2])))

  ## To calculate distances from average point
  nldr_with_avg_all <- dplyr::inner_join(bin_val_hexagons , nldr_df_with_hex_id,
                                         by = c("hb_id" = "hb_id"))

  col_names <- c(names(bin_val_hexagons), names(nldr_df_with_hex_id)[1:2], "distance")

  ## Initialize the vectors to store data
  hexids <- integer(0)
  emb1_vec <- numeric(0)
  emb2_vec <- numeric(0)
  weight_vec <- numeric(0)

  for(hb_id in unique(nldr_with_avg_all$hb_id)){

    ## These are the weights for weighted mean
    weighted_mean_df <- nldr_with_avg_all |>
      dplyr::filter(hb_id == hb_id) |>
      cal_2d_dist(start_x = col_names[2], start_y = col_names[3], end_x = col_names[4],
                  end_y = col_names[5], select_vars = col_names)

    hexids <- c(hexids, weighted_mean_df$hb_id)
    emb1_vec <- c(emb1_vec, weighted_mean_df[[rlang::as_string(rlang::sym(col_names[4]))]])
    emb2_vec <- c(emb2_vec, weighted_mean_df[[rlang::as_string(rlang::sym(col_names[5]))]])
    weight_vec <- c(weight_vec, 1/ (weighted_mean_df$distance + 0.05))

  }

  weight_list <- list(hb_id = hexids, emb1_vec = emb1_vec, emb2_vec = emb2_vec,
                      weight_vec = weight_vec)
  names(weight_list) <- c("hb_id", names(nldr_df_with_hex_id)[1:2], "weights")

  return(weight_list)

}


## ----echo=FALSE---------------------------------------------------------------
weighted_highD_data <- function(training_data, nldr_df_with_hex_id,
                                column_start_text = "x") {
  ## Remove ID column from training data
  training_data <- training_data |>
    dplyr::select(-ID)

  ## Join training data with 2D embeddings
  df_all <- dplyr::bind_cols(training_data, nldr_df_with_hex_id)

  ## To obtain weights corresponding to 2D embeddings
  weight_df <- as.data.frame(do.call(cbind,
                                     compute_weights(nldr_df_with_hex_id = nldr_df_with_hex_id)))

  ## Initialize the columns that need to use for joining
  joined_col_names <- names(nldr_df_with_hex_id)[1:2]

  ## To join the training data, 2D embeddings and weights
  weighted_mean_all <- dplyr::inner_join(df_all, weight_df,
                                         by = c("hb_id" = "hb_id",
                                                stats::setNames(joined_col_names,
                                                                joined_col_names)))
  ## List to store weighted means
  weighted_mean_df_list <- list()

  for (j in 1:NCOL(training_data)) {

    ## To compute weighted mean across all high-D coordinates
    weighted_mean_df_list[[j]] <- weighted_mean_all |>
      dplyr::select(hb_id, names(training_data)[j], weights) |>
      dplyr::group_by(hb_id) |>
      dplyr::summarise(dplyr::across(names(training_data)[j], ~ weighted.mean(., weights)))

  }

  ## To combine the elements given in the list
  weighted_mean <- Reduce(function(dtf1,dtf2) dplyr::full_join(dtf1,dtf2,by="hb_id"),
                          weighted_mean_df_list)


  ## Column names start with x
  weighted_mean <- weighted_mean |>
    dplyr::select(hb_id, tidyselect::starts_with(column_start_text))

  return(weighted_mean)
}


## ----echo=FALSE---------------------------------------------------------------

extract_hexbin_mean <- function(nldr_df_with_hex_id, counts_df) {

  ## To arrange the hexagon IDs
  counts_df <- counts_df |>
    dplyr::arrange(hb_id)

  ## To compute hexagonal bin means
  hex_mean_df <- nldr_df_with_hex_id |>
    dplyr::group_by(hb_id) |>
    dplyr::summarise(dplyr::across(tidyselect::everything(), mean)) |>
    dplyr::arrange(hb_id) |>
    dplyr::filter(hb_id %in% counts_df$hb_id) |>
    dplyr::mutate(std_counts = counts_df$std_counts)

  ## Rename columns
  names(hex_mean_df) <- c("hexID", "c_x", "c_y", "std_counts")

  return(hex_mean_df)
}


## -----------------------------------------------------------------------------
bin_list <- calc_bins(data = s_curve_noise_umap_scaled, 
                      x = "UMAP1", y = "UMAP2", 
                      hex_size = NA, buffer_x = NA, 
                      buffer_y = NA)
num_bins_x <- bin_list$num_x
num_bins_y <- bin_list$num_y

hb_obj <- hex_binning(data = s_curve_noise_umap_scaled, 
                      x = "UMAP1", y = "UMAP2", 
                      num_bins_x = num_bins_x, num_bins_y = num_bins_y, 
                      x_start = NA, y_start = NA, 
                      buffer_x = NA, buffer_y = NA, 
                      hex_size = NA, col_start = "UMAP")


all_centroids_df <- as.data.frame(do.call(cbind, hb_obj$centroids))
counts_df <- as.data.frame(do.call(cbind, hb_obj$std_cts))
nldr_df_with_hex_id <- as.data.frame(do.call(cbind, hb_obj$data_hb_id))

## To obtain bin centroids
df_bin_centroids <- extract_hexbin_mean(nldr_df_with_hex_id = nldr_df_with_hex_id,
                                             counts_df = counts_df)

df_all <- dplyr::bind_cols(s_curve_noise_training |> dplyr::select(-ID), nldr_df_with_hex_id)

ggplot() + 
  geom_trimesh(data = df_bin_centroids, mapping = aes(x = c_x, y = c_y)) +
  coord_fixed()

tr1_object <- tri_bin_centroids(hex_df = df_bin_centroids, x = "c_x", y = "c_y")
tr_from_to_df <- gen_edges(tri_object = tr1_object)
distance_df <- cal_2d_dist(tr_coord_df = tr_from_to_df, 
                           start_x = "x_from", start_y = "y_from", 
                           end_x = "x_to", end_y = "y_to", 
                           select_vars = c("from", "to", "distance"))


## averaged high-D data
df_bin <- weighted_highD_data(training_data = s_curve_noise_training, nldr_df_with_hex_id = nldr_df_with_hex_id, column_start_text = "x")

vis_lg_mesh(distance_edges = distance_df, benchmark_value = 1,
tr_coord_df = tr_from_to_df, distance_col = "distance")

vis_rmlg_mesh(distance_edges = distance_df, benchmark_value = 1,
tr_coord_df = tr_from_to_df, distance_col = "distance")

show_langevitour(df = df_all, df_b = df_bin, 
                 df_b_with_center_data = df_bin_centroids, 
                 benchmark_value = 1, distance = distance_df, 
                 distance_col = "distance", 
                 use_default_benchmark_val = FALSE, col_start = "x")

