---
title: "quollr: An R Package for Visualizing 2D Models from Nonlinear Dimension Reductions in High Dimensional Space"
abstract: >
  Non-Linear Dimension Reduction (NLDR) techniques have emerged as powerful tools to visualize high-dimensional ($p-D$) data in low-diemnsioanl space. However, their complexity and hyperparameter choices may lead to distrustful or misleading results. The R package \CRANpkg{quollr} is developed as a new tool to help to determine which method, which hyperparameter choice provide the most accurate representation of $p-D$ data. Clustering data from \CRANpkg{cardinalR} package, is used to illustrate the algorithm and its use within the package.
draft: true
author:  
  - name: Jayani P.G. Lakshika
    affiliation: Monash University
    address: Department of Econometrics and Business Statistics, VIC 3800 Australia
    url: https://jayanilakshika.netlify.app/
    orcid: 0000-0002-6265-6481
    email:  \email{jayani.piyadigamage@monash.edu}
  - name: Dianne Cook
    affiliation: Monash University
    address: Department of Econometrics and Business Statistics, VIC 3800 Australia
    url: http://www.dicook.org/
    email: dicook@monash.edu
    orcid: 0000-0002-3813-7155
  - name: Paul Harrison
    affiliation: Monash University
    address: MGBP, BDInstitute, VIC 3800 Australia
    email: paul.harrison@monash.edu
    orcid: 0000-0002-3980-268X
  - name: Michael Lydeamore
    affiliation: Monash University
    address: Department of Econometrics and Business Statistics, VIC 3800 Australia
    email: michael.lydeamore@monash.edu
    orcid: 0000-0001-6515-827X
  - name: Thiyanga S. Talagala
    affiliation: University of Sri Jayewardenepura
    address: Department of Statistics, Gangodawila, Nugegoda 10100 Sri Lanka
    url: https://thiyanga.netlify.app/
    email: ttalagala@sjp.ac.lk
    orcid: 0000-0002-0656-9789
type: package
creative_commons: CC BY
date: "`r Sys.Date()`"
preamble: >
  \usepackage{amsmath}
  \usepackage{array}
output: 
 rjtools::rjournal_web_article:
    css: "style.css"
    keep_md: true
bibliography: RJreferences.bib
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
options(repos = "https://cloud.r-project.org") ## set up CRAN mirror
knitr::opts_chunk$set(
  echo = FALSE, 
  cache=FALSE, 
  message=FALSE, 
  warning=FALSE,
  out.width = "100%")

```

```{r load-libraries}
library(quollr)
library(tibble)
library(knitr)
library(kableExtra)
library(ggplot2)
library(dplyr)
library(ggbeeswarm)
library(patchwork)
library(Rtsne)
library(readr)
library(tools)

set.seed(20240110)
```

```{r plot-theme}
theme_set(theme_linedraw() +
   theme(
     aspect.ratio = 1,
     plot.background = element_rect(fill = 'transparent', colour = NA),
     plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
     panel.background = element_rect(fill = 'transparent', 
                                     colour = NA),
     panel.grid.major = element_blank(), 
     panel.grid.minor = element_blank(), 
     axis.title.x = element_blank(), axis.title.y = element_blank(),
     axis.text.x = element_blank(), axis.ticks.x = element_blank(),
     axis.text.y = element_blank(), axis.ticks.y = element_blank(),
     legend.background = element_rect(fill = 'transparent', 
                                      colour = NA),
     legend.key = element_rect(fill = 'transparent', 
                               colour = NA),
     legend.position = "none", 
     legend.title = element_text(size=5), 
     legend.text = element_text(size=4),
     legend.key.height = unit(0.25, 'cm'),
     legend.key.width = unit(0.25, 'cm')
   )

)
```

<!-- 20 pages-->

# Introduction

<!-- research gap: add about hexbin pkg, and emphasize that in our package provide regular hexagons-->
<!-- objective: introduce a new tool to help to determine which method, which parameter choice provide the most useful representation of high-D data.--> 
<!--intro with S-curve with 5 methods-->

This paper presents the R package, `quollr` which introduce a new tool in determining which NLDR technique and which hyperparameter choice gives most accurate representation of $p-D$ data. The methodology of the algorithm is explained in *cite the methodology paper*. Furthermore, the `quollr` package enables users to perform hexagonal binning [@dan2023], resulting in the generation of regular hexagons. The software is available from the Comphrehensive R Archive Network (CARN) at [https://CRAN.R-project.org/package=quollr](https://CRAN.R-project.org/package=quollr).

The paper is organized as follows. In next section, introduces the implementation of `quollr` package on CRAN, including demonstration of the package's key functions and visualization capabilities. We illustrate the algorithm's functionality to study clustering data set in **Application** section, and describe a visual heuristic to describe parameter selection. Finally, we give a brief conclusion of the paper and discuss potential opportunities for use of our algorithm.

# Implementation

The package can be installed from CRAN:

```r
install.packages("quollr")
```

The development version can be installed from GitHub:

```r
devtools::install_github("JayaniLakshika/quollr")
```

## Package dependencies

Understanding the dependencies of the "quollr" package is essential for smooth operation and error prevention. The following dependencies refer to the other R packages that `quollr` relies on to execute its functions effectively. 

```{r}
package_dependencies("quollr")
```

## Usage

The following demonstration of the package's functionality assumes `quollr` has been loaded. We also want to load the built-in data sets `s_curve_noise_training` and `s_curve_noise_umap`.

The mains steps for the algorithm can be executed by the main function `fit_highd_model()`, or can be run separately for more flexibility. When constructing the 2D model, the user can choose either to fir the 2D model with hexagonal bin centroids or bin means using `is_bin_centroid` argument.

```{r, echo=TRUE, eval=FALSE}
model_object <- fit_highd_model( training_data = s_curve_noise_training, 
                                 nldr_df_with_id = s_curve_noise_umap_scaled, 
                                 x = "UMAP1", y = "UMAP2", 
                                 num_bins_x = num_bins_x_s_curve, 
                                 num_bins_y = num_bins_y_s_curve, 
                                 x_start = NA, y_start = NA, 
                                 buffer_x = NA, buffer_y = NA, 
                                 hex_size = hex_size_s_curve,
                                 is_bin_centroid = TRUE,
                                 is_rm_lwd_hex = FALSE, 
                                 benchmark_to_rm_lwd_hex = NA, 
                                 col_start_2d = "UMAP", 
                                 col_start_highd = "x")
```

<!-- add about main function to gen 2D and highD models-->
<!--Discuss the model can be generated with bin centroids or bin means-->

```{r}

## Decide by looking at MSE plot
num_bins_x_s_curve <- 8
num_bins_y_s_curve <- 14
hex_size_s_curve <- 0.1
hb_obj_s_curve <- hex_binning(data = s_curve_noise_umap_scaled, x = "UMAP1", 
                      y = "UMAP2", num_bins_x = num_bins_x_s_curve, 
                      num_bins_y = num_bins_y_s_curve, x_start = NA, y_start = NA, 
                      buffer_x = NA, buffer_y = NA, hex_size = hex_size_s_curve, col_start = "UMAP")
## Data set with all possible centroids in the hexagonal grid
all_centroids_df <- as.data.frame(do.call(cbind, hb_obj_s_curve$centroids))
## Generate all coordinates of hexagons
hex_grid <- as.data.frame(do.call(cbind, hb_obj_s_curve$hex_poly))
## To obtain the standardise counts within hexbins
counts_df <- as.data.frame(do.call(cbind, hb_obj_s_curve$std_cts))
df_bin_centroids <- extract_hexbin_centroids(centroids_df = all_centroids_df, 
                                             counts_df = counts_df)
## remove low-density hexagons
hex_grid_with_counts <- dplyr::left_join(hex_grid, counts_df, by = c("hex_poly_id" = "hb_id"))

centroid_plot <- ggplot(data = all_centroids_df, aes(x = c_x, y = c_y)) +
  geom_point(color = "#33a02c") +
  coord_fixed() +
  theme_void() +
  theme(plot.title = element_text(size = 7, hjust = 0.5,
vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), #change legend key width
        legend.title = element_text(size=8), #change legend title font size
        legend.text = element_text(size=6)) 

full_grid <- ggplot(data = hex_grid, aes(x = x, y = y)) +
  geom_polygon(fill = "#ffffff", color = "black", aes(group = hex_poly_id)) +
  geom_point(data = all_centroids_df, aes(x = c_x, y = c_y), color = "#33a02c") +
  coord_fixed() +
  theme_void() +
  theme(legend.position="none", legend.direction="horizontal", plot.title = element_text(size = 7, hjust = 0.5,
vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), #change legend key width
        legend.title = element_text(size=8), #change legend title font size
        legend.text = element_text(size=6)) 

std_pts_grid <-  ggplot(data = hex_grid_with_counts, aes(x = x, y = y)) +
  geom_polygon(color = "black", aes(group = hex_poly_id, fill = std_counts)) +
  geom_point(data = s_curve_noise_umap_scaled, aes(x = UMAP1, y = UMAP2), color = "black", alpha = 1) +
  scale_fill_viridis_c(direction = -1, na.value = "#ffffff", option = "C") +
  coord_fixed() +
  theme_void() +
  theme(legend.position="none", legend.direction="horizontal", plot.title = element_text(size = 7, hjust = 0.5,
vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), #change legend key width
        legend.title = element_text(size=8), #change legend title font size
        legend.text = element_text(size=6)) 

umap_data_with_hb_id <- as.data.frame(do.call(cbind, hb_obj_s_curve$data_hb_id))
  
model_object <- fit_highd_model( training_data = s_curve_noise_training, 
                                 nldr_df_with_id = s_curve_noise_umap_scaled, 
                                 x = "UMAP1", y = "UMAP2", 
                                 num_bins_x = num_bins_x_s_curve, 
                                 num_bins_y = num_bins_y_s_curve, 
                                 x_start = NA, y_start = NA, 
                                 buffer_x = NA, buffer_y = NA, 
                                 hex_size = hex_size_s_curve,
                                 is_rm_lwd_hex = FALSE, 
                                 benchmark_to_rm_lwd_hex = NA, 
                                 col_start_2d = "UMAP", 
                                 col_start_highd = "x")
df_bin_centroids_s_curve <- model_object$df_bin_centroids
df_bin_s_curve <- model_object$df_bin



## Triangulate bin centroids
tr1_object_s_curve <- tri_bin_centroids(df_bin_centroids_s_curve, x = "c_x", y = "c_y")
tr_from_to_df_s_curve <- gen_edges(tri_object = tr1_object_s_curve)
## Compute 2D distances
distance_s_curve <- cal_2d_dist(tr_coord_df = tr_from_to_df_s_curve, 
                             start_x = "x_from", start_y = "y_from", 
                             end_x = "x_to", end_y = "y_to", 
                             select_vars = c("from", "to", "distance"))

## To find the benchmark value
benchmark_s_curve <- find_lg_benchmark(distance_edges = distance_s_curve, distance_col = "distance")
benchmark_s_curve <- 0.5

trimesh_s_curve <- ggplot(df_bin_centroids_s_curve, aes(x = c_x, y = c_y)) +
  geom_trimesh() +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'a', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3) +
  labs(colour = "")

trimesh_colored_s_curve_umap <- vis_lg_mesh(distance_edges = distance_s_curve, benchmark_value = benchmark_s_curve,
tr_coord_df = tr_from_to_df_s_curve, distance_col = "distance") 

trimesh_colored_s_curve_umap <- trimesh_colored_s_curve_umap +
  theme_linedraw() +
  theme(legend.position = "bottom", plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'b', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3) +
  labs(colour = "")

trimesh_removed_s_curve_umap <- vis_rmlg_mesh(distance_edges = distance_s_curve, benchmark_value = benchmark_s_curve, tr_coord_df = tr_from_to_df_s_curve, distance_col = "distance")
trimesh_removed_s_curve_umap <- trimesh_removed_s_curve_umap +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'c', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

trimesh_removed_s_curve_umap_0.3 <- vis_rmlg_mesh(distance_edges = distance_s_curve, benchmark_value = 0.3, tr_coord_df = tr_from_to_df_s_curve, distance_col = "distance")
trimesh_removed_s_curve_umap_0.3 <- trimesh_removed_s_curve_umap_0.3 +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'a', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

trimesh_removed_s_curve_umap_0.8 <- vis_rmlg_mesh(distance_edges = distance_s_curve, benchmark_value = 0.8, tr_coord_df = tr_from_to_df_s_curve, distance_col = "distance")
trimesh_removed_s_curve_umap_0.8 <- trimesh_removed_s_curve_umap_0.8 +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'b', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

df_all_s_curve <- dplyr::bind_cols(s_curve_noise_training |> dplyr::select(-ID), umap_data_with_hb_id)

# show_langevitour(df_all_s_curve, df_bin_s_curve, df_bin_centroids_s_curve, benchmark_s_curve, distance_s_curve, "distance", col_start = "x")

### Define type column
df <- df_all_s_curve |>
  dplyr::select(tidyselect::starts_with("x")) |>
  dplyr::mutate(type = "data") ## original dataset

df_b <- df_bin_s_curve |>
  dplyr::filter(hb_id %in% df_bin_centroids_s_curve$hexID) |>
  dplyr::mutate(type = "model") ## Data with summarized mean
## Reorder the rows of df_b according to the hexID order in df_b_with_center_data
df_b <- df_b[match(df_bin_centroids_s_curve$hexID, df_b$hb_id),] |>
  dplyr::select(-hb_id)
df_exe <- dplyr::bind_rows(df_b, df)
## Set the maximum difference as the criteria
distance_df_small_edges <- distance_s_curve |>
  dplyr::filter(distance < benchmark_s_curve)
## Since erase brushing is considerd.
tour <- langevitour::langevitour(df_exe[1:(length(df_exe)-1)],
                         lineFrom = distance_df_small_edges$from,
                         lineTo = distance_df_small_edges$to,
                         group = df_exe$type, pointSize = append(rep(0, NROW(df_b)), rep(1, NROW(df))),
                         levelColors = c("#6a3d9a", "#33a02c"))
```

## Constructing the 2D model

### Preprocessing
<!--Discuss scaling the NLDR data-->

The function `gen_scaled_data()` is used to prepare the NLDR data to fit within the bounds required for regular hexagonal binning, ensuring effective visualization.

```{r, echo=TRUE, eval=FALSE}
s_curve_noise_umap_scaled <- gen_scaled_data(data = s_curve_noise_umap, x = "UMAP1", y = "UMAP2")
```

<!-- add plot before and after scaling NLDR data-->

### Binning data 

**Step 1: Compute hexagonal grid configurations**

```{r, echo=TRUE, eval=FALSE}
bin_list <- calc_bins(data = s_curve_noise_umap_scaled, x = "UMAP1", 
                      y = "UMAP2", hex_size = NA, buffer_x = NA, buffer_y = NA)

num_bins_x <- bin_list$num_x
num_bins_y <- bin_list$num_y
```

The mains steps for the hexagonal binning algorithm can be executed by the main function `hex_binning()`, or can be run separately for more flexibility.
<!-- add about main function for hexagonal binning-->

```{r, echo=TRUE, eval=FALSE}
hb_obj <- hex_binning(data = s_curve_noise_umap_scaled, x = "UMAP1", 
                      y = "UMAP2", num_bins_x = num_bins_x, 
                      num_bins_y = num_bins_y, x_start = NA, y_start = NA, 
                      buffer_x = NA, buffer_y = NA, hex_size = NA, 
                      col_start = "UMAP")

```

```{r, out.width="100%", fig.cap = "Illustration of key steps of the hexagonal bining algorithm: (a) first, all hexagonal bin centroids are created; (b) second, full hexagon grid is created; and (c) finally, assign the data to hexagons. The centroids are used to generate hexagonal coordinates. Once the full hexagonal grid is generated, by computing the 2D euclidean distance from each NLDR points to hexagonal bin centroids, the nearest NLDR points are allocated to the nearest hexagoanl bin."}

centroid_plot + full_grid + std_pts_grid +
  plot_annotation(tag_levels = 'a') +
  plot_layout(ncol = 3) &
  theme(plot.tag = element_text(size = 8))
```

**Step 2: Generate the hexagonal bin centroids**

```{r, echo=TRUE, eval=FALSE}
centroid_list <- gen_centroids(data = s_curve_noise_umap_scaled, x = "UMAP1", 
                               y = "UMAP2", num_bins_x = num_bins_x,
                               num_bins_y = num_bins_y, x_start = NA,
                               y_start = NA, buffer_x = NA, buffer_y = NA, 
                               hex_size = NA)

all_centroids_df <- as.data.frame(do.call(cbind, centroid_list))
```

**Step 3: Create the hexagonal grid**

```{r, echo=TRUE, eval=FALSE}
all_hex_coordinates_list <- gen_hex_coord(centroids_df = all_centroids_df,
                                            hex_size = NA)
```

**Step 4: Assign NLDR data to hexagons**

```{r, echo=TRUE, eval=FALSE}
df_with_hb_id_list <- assign_data(data = s_curve_noise_umap_scaled |> 
                                    dplyr::select(-ID), 
                                  centroid_df = all_centroids_df, 
                                  col_start = "UMAP")
umap_data_with_hb_id <- as.data.frame(do.call(cbind, df_with_hb_id_list))
```

```{r, echo=TRUE, eval=FALSE}
std_counts_list <- compute_std_counts(data_hex_id = df_with_hex_id)
counts_df <- as.data.frame(do.call(cbind, std_counts_list))
```


### Obtain bin centroids/ means

To obtain hexagonal bin centroids, `extract_hexbin_centroids()`is used. The function `extract_hexbin_mean()` is used to obtain average within each hexagon. 

```{r, echo=TRUE, eval=FALSE}
df_bin_centroids <- extract_hexbin_centroids(centroids_df = all_centroids_df, 
                                             counts_df = counts_df)
```

```{r, echo=TRUE, eval=FALSE}
df_bin_means <- extract_hexbin_mean(nldr_df_with_hex_id = umap_with_hb_id,
                                        counts_df = counts_df)
```

### Triangulate bin centroids/ means

The `tri_bin_centroids()` is used to do triangulate bin centroids/ bin means. Then, `gen_edges()` compute the edges to obtain the triangular mesh which is the 2D model.

```{r, echo=TRUE, eval=FALSE}
tr1_object <- tri_bin_centroids(hex_df = df_bin_centroids, x = "c_x", y = "c_y")
tr_from_to_df <- gen_edges(tri_object = tr1_object)
```

## Lifting the model into high dimensions

The $p$-D model is generated by `avg_highd_data()` by passing the $p$-D data. 

```{r, echo=TRUE, eval=FALSE}
df_all <- dplyr::bind_cols(s_curve_noise_training |> dplyr::select(-ID),
                           umap_data_with_hb_id)

df_bin <- avg_highd_data(data = df_all, col_start = "x")
```

## Model parameters

<!--discuss about default settings-->

Mainly there are two model parameter need to consider: benchmark value to remove the low-density hexagons, and benchmark value to remove the long edges. `find_low_dens_hex()` is used to find the hexagons which contains less number of points by considering the density of their neighboring points as well. In here, user can first decide which are the low-density hexagons and pass them to this function to check whether these removal of low-density hexagons can affect the model fit by looking at the the neighbors. On the other hand, `find_lg_benchmark()` function is used to compute the threshold for removing long edges.

```{r, echo=TRUE, eval=FALSE}
df_bin_centroids_low <- df_bin_centroids |> dplyr::filter(std_counts <= 0.43)

low_dens_hex <- find_low_dens_hex(df_bin_centroids_all = df_bin_centroids, 
                  num_bins_x = num_bins_x, 
                  df_bin_centroids_low = df_bin_centroids_low)
```

```{r, echo=TRUE, eval=FALSE}
distance_df <- cal_2d_dist(tr_coord_df = tr_from_to_df, start_x = "x_from", 
                           start_y = "y_from", end_x = "x_to", end_y = "y_to",
                           select_vars = c("from", "to", "distance"))

benchmark_val <- find_lg_benchmark(distance_edges = distance_df, distance_col = "distance")
```

## Prediction

`predict_emb()` function is used to predict 2D embedding for a new $p$-D data point using the fitted model. This function is useful to predict 2D embedding irrespective of the NLDR technique.

```{r}
## Prediction for training data
pred_emb_list_training <- predict_emb(test_data = s_curve_noise_training, 
                             df_bin_centroids = df_bin_centroids_s_curve, 
                             df_bin = df_bin_s_curve, type_NLDR = "UMAP")
pred_df_training <- as.data.frame(do.call(cbind, pred_emb_list_training))

pred_points_training <- ggplot(data = s_curve_noise_umap_scaled, aes(x = UMAP1, y = UMAP2)) +
  geom_point() +
  geom_point(data = pred_df_training, aes(x = pred_UMAP_1, y = pred_UMAP_2), colour = "#de2d26") +
  annotate(geom = 'text', label = 'a', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

## Prediction for test data
pred_emb_list_test <- predict_emb(test_data = s_curve_noise_test, 
                             df_bin_centroids = df_bin_centroids_s_curve, 
                             df_bin = df_bin_s_curve, type_NLDR = "UMAP")
pred_df_test <- as.data.frame(do.call(cbind, pred_emb_list_test))

pred_points_test <- ggplot(data = s_curve_noise_umap_scaled, aes(x = UMAP1, y = UMAP2)) +
  geom_point() +
  geom_point(data = pred_df_test, aes(x = pred_UMAP_1, y = pred_UMAP_2), colour = "#de2d26") +
  annotate(geom = 'text', label = 'b', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

```

```{r, out.width="100%", fig.cap = "Predicted 2D embedding overlaid with UMAP embedding of S-curve training data: (a) prediction of 2D embeddings for S-curve training data, and (b) prediction of 2D embeddings for S-curve test data. Once the high-D model is generated, first, for the new data points the nearest high-D mappings of hexagonal bin centroids find by computing Euclidean distance. Then, mapping back the 2D hexagonal bin centroids gives the prediction for the new data points."}

pred_points_training + pred_points_test +
  plot_layout(ncol = 2) &
  theme(plot.tag = element_text(size = 8))
```

## Compute residuals and Mean Square Error (MSE)

As a Goodness of fit statistics for the model, `gen_summary()` is used to compute residuals and MSE. For the fitted model, how residuals and MSE is changing is shown in Figure 2.

```{r, echo=TRUE}
gen_summary(test_data = s_curve_noise_training, prediction_df = pred_df_training,
df_bin = df_bin_s_curve, col_start = "x")
```

```{r, echo=TRUE}
gen_summary(test_data = s_curve_noise_test, prediction_df = pred_df_test,
df_bin = df_bin_s_curve, col_start = "x")
```

<!--add a plot with total bins Vs MSE, non-empty bins Vs Error-->

## Visualizations

The package provides four basic visualizations which includes three visualizations regarding 2D model (static vis) and one is regrading $p$-D model (dynamic vis). Each visualization can be done their own functions which describes in this section.

<!--add trimesh, colored trimesh, removed edge trimesh, screenshots from langevitour with the model and data-->

### 2D model visualization

<!--2D model vis: triangular mesh, colored trimesh, removed edge trimesh-->
To visualize the 2D model, mainly three functions are used. As shown in Figure \@ref(fig:mesh-plots)a, `geom_trimesh()` to visualize the triangular mesh by adding a new layer to `ggplot()`. After identifying benchmark value to remove long edge, `vis_lg_mesh()` is used to visualize the triangular mesh by coloring the small and long edges. As shown in Figure \@ref(fig:mesh-plots)b, the small and long edges are colored by black and red respectively. Following this, `vis_rmlg_mesh()` is used to visualize smoothed 2D model which is the 2D model after removing the long edges (see Figure \@ref(fig:mesh-plots)c). In `vis_lg_mesh()` and `vis_rmlg_mesh()`, `benchmark_value` argument controls the edge removal in 2D. Using small value of `benchmark_value`, will produce a triangular mesh with missing data structure; for example `benchmark_value = 0.3` shows two clusters rather than continuous structure, while `benchmark_value = 0.8` creates long edges and mislead the data structure in $p-D$ space.

```{r mesh-plots, out.width="100%", fig.cap="Visualization of model generated for UMAP embedding for S-curve data in 2D space: (a) triangular mesh, (b), triangular mesh colored by edge type, and (c) triangular mesh after removing the long edges. The edges which has the length greater than $0.5$ are assigned as long edges. To obtain smooth representation in 2D space, the long edges are removed."}

trimesh_s_curve + trimesh_colored_s_curve_umap + trimesh_removed_s_curve_umap +
  plot_layout(ncol = 3) &
  theme(plot.tag = element_text(size = 8))
```

```{r mesh-diffplots, out.width="100%", fig.cap="Visualization of model generated for UMAP embedding for S-curve data in 2D space with different benchmark value applied to remove long edges: (a) benchmark_value = 0.3, and (b) benchmark_value = 0.8. Small benchmark values will generate misleading data structures in 2D space, while; large bechmark value will generate more long edges in $p-D$ and miinterpret the $p-D$ data structure."}

trimesh_removed_s_curve_umap_0.3 + trimesh_removed_s_curve_umap_0.8 +
  plot_layout(ncol = 2) &
  theme(plot.tag = element_text(size = 8))
```

### p-D model visualization

<!--highD model vis: langevitour with the model-->

The $p$-D model overlaid on data is visualized by the function `show_langevitour()`. This is a useful dynamic visualization result to validate visually whether the model fits the data well or not.

```{r, echo=TRUE, eval=FALSE}
tour <- show_langevitour(df = df_all, df_b = df_bin, 
                 df_b_with_center_data = df_bin_centroids, benchmark_value = 0.5, 
                 distance = distance_df, distance_col = "distance", 
                 use_default_benchmark_val = FALSE, col_start = "x")
```

<!--need to add screenshots of the frames and add the link of the video-->
```{r tour-s-curve}
tour
```

<!--
## Usage

-   dependencies

-   basic example-->

## Tests

All functions have tests written and implemented using the \CRANpkg{testthat} [@testthat] in R.

# Application

We illustrate the use of the algorithm by applying it to `clusters_different_shapes_diff_num_points` dataset in `cardinalR` package. The tSNE is used in the example for the demonstration (see Figure \@ref(fig:tsne-clust)). 

<!--select a dataset from cardinalR-->
<!-- diff shape clusters-->
<!-- talk with best fit-->

```{r, echo=FALSE}
clusters_different_shapes_diff_num_points <- function(sample_size = 400, with_seed = NULL, cluster_size_vec = c(50, 50, 50, 50, 100, 100), num_gussian_clusters = 4, num_non_gaussian_clusters = 2,
                                      cluster_sd_gau = 0.05, cluster_sd_non_gau = 0.1, num_dims = 7, a = 2, b = 4) {


  # To check the seed is not assigned
  if (!is.null(with_seed)) {
    set.seed(with_seed)
  }

  num_clusters <- num_gussian_clusters + num_non_gaussian_clusters



  ## Generate Gaussian clusters

  # Create a vector of possible values (0 and 1)
  values <- c(0, 1)

  # Create an expanded grid with 0's and 1's
  mean_val_grid <- tidyr::expand_grid(!!!setNames(rep(list(values), num_dims),
                                                  paste0("mean_dim", 1:num_dims)))

  # To select combinations for assigned number of clusters

  mean_val_grid_gau <- mean_val_grid |>
    dplyr::slice_sample(n = num_gussian_clusters)

  mean_val_grid_non_gau <- mean_val_grid |>
    dplyr::slice_sample(n = num_non_gaussian_clusters)


  # To generate empty tibble
  column_names <- paste0(rep("x", num_dims), 1:num_dims)
  df <- tibble(!!!setNames(rep(list(NULL), length(column_names)), column_names))

  for (i in 1:num_gussian_clusters) {

    # To filter the mean values for specific cluster
    mean_val_for_cluster <- mean_val_grid_gau |>
      dplyr::filter(dplyr::row_number() == i) |>
      unlist(use.names = FALSE)

    # Initialize an empty list to store the vectors with column
    # values
    dim_val_list <- list()

    for (j in 1:num_dims) {

      dim_val_list[[column_names[j]]] <- rnorm(cluster_size_vec[i], mean = mean_val_for_cluster[j],
                                               sd = cluster_sd_gau)

    }
    # To generate a tibble for a cluster
    df_gau_cluster <- tibble::as_tibble(dim_val_list)

    df <- dplyr::bind_rows(df, df_gau_cluster)

  }

  

  for (i in 1:num_non_gaussian_clusters) {
    
    phi <- runif(cluster_size_vec[(num_clusters - i)], max = 2*pi)
    rho <- sqrt(runif(cluster_size_vec[(num_clusters - i)]))

    # To filter the mean values for specific cluster
    presence_of_elipse_cluster <- mean_val_grid_non_gau |>
      dplyr::filter(dplyr::row_number() == i) |>
      unlist(use.names = FALSE)

    # Initialize an empty list to store the vectors with column
    # values
    dim_val_list_n <- list()

    for (j in 1:num_dims) {
      if(presence_of_elipse_cluster[j] == 1){
        dim_val_list_n[[column_names[j]]] <- sqrt(a)*rho*cos(phi) + b
        ## Surface of poolar coordinate
      } else {
        dim_val_list_n[[column_names[j]]] <- rnorm(cluster_size_vec[(num_clusters - i)], mean = 0,
                                                   sd = cluster_sd_non_gau)

      }

    }
    # To generate a tibble for a cluster
    df_non_gau_cluster <- tibble::as_tibble(dim_val_list_n)

    df <- dplyr::bind_rows(df, df_non_gau_cluster)

  }

  df

}
```

<!--need to add screen shots of the original data-->

```{r}
clust_df <- clusters_different_shapes_diff_num_points(sample_size = 1500, with_seed = NULL, cluster_size_vec = c(250, 150, 150, 150, 350, 450), num_gussian_clusters = 4, num_non_gaussian_clusters = 2, cluster_sd_gau = 0.2, cluster_sd_non_gau = 0.3, num_dims = 7, a = 2, b = 4)

langevitour::langevitour(clust_df)

clust_df <- clust_df |>
  dplyr::mutate(ID = row_number())
```

```{r}
tSNE_fit <- clust_df |>
  dplyr::select(-ID) |>
  dplyr::select(where(is.numeric)) |>
  Rtsne::Rtsne(perplexity = 39, pca = FALSE, pca_center = FALSE, normalize = FALSE, dims = 2)

tSNE_df <- tSNE_fit$Y |> 
  tibble::as_tibble(.name_repair = "unique") |>
  dplyr::mutate(ID = clust_df$ID)

names(tSNE_df) <- c("tSNE1", "tSNE2", "ID")

tSNE_df_plot <- tSNE_df |>
  ggplot(aes(x = tSNE1,
             y = tSNE2))+
  geom_point(alpha=0.5, colour="#e41a1c", size = 0.5) +
  coord_equal() +
  theme(plot.title = element_text(hjust = 0.5, size = 18, face = "bold"),
        axis.text = element_text(size = 5),
        axis.title = element_text(size = 7))
```

```{r tsne-clust, out.width="100%", fig.cap="tSNE representation of data with perplexity: 39. Is this representation accurately capture the structure in high dimensions?"}
tSNE_df_plot
```

## Selecting parameter values for hexagonal binning

We previously introduced three key parameters, *hex_size*, *x_start*, and *y_start*, in our explanation of the algorithm. While their best choice is unknown, a visualization tool enables their tuning such that user can select reasonable values. 

Consider the relationships between *total number of bins*, *starting point*, and MSE. Increase of *total number of bins* usually reduces the MSE.  

<!--hex_size, starting point (x_start, y_start)-->
<!--talk about to use bin centroids or bin means-->

<!-- MSE plot to find which is the effective number of bins to use-->
```{r}
tsne_gau_scaled <- as.data.frame(do.call(cbind, gen_scaled_data(data = tSNE_df, 
                                    x = "tSNE1", y = "tSNE2"))) |>
  dplyr::rename(c("tSNE1" = "scaled_tSNE1", 
                  "tSNE2" = "scaled_tSNE2")) |>
  dplyr::mutate(ID = 1:NROW(tSNE_df))    
## tSNE
hex_size_vec <- seq(0.02, 2, by = 0.01)
vec <- stats::setNames(rep("", 6), c("num_bins", "aic", "mse", "num_bins_x", "num_bins_y", "hex_size"))  ## Define column names
mse_df_gau <- dplyr::bind_rows(vec)[0, ]
mse_df_gau <- mse_df_gau |>
  dplyr::mutate_if(is.character, as.numeric)
for (i in 1:length(hex_size_vec)) {
  
  num_bin_list <- calc_bins(data = tsne_gau_scaled, 
            x = "tSNE1", y = "tSNE2", 
            hex_size = hex_size_vec[i], buffer_x = NA, buffer_y = NA)
  
  num_bins_x <- num_bin_list$num_x
  num_bins_y <- num_bin_list$num_y
  
  model_object <- fit_highd_model( training_data = clust_df, 
                                   nldr_df_with_id = tsne_gau_scaled, 
                                   x = "tSNE1", y = "tSNE2", 
                                   num_bins_x = num_bins_x, 
                                   num_bins_y = num_bins_y, 
                                   x_start = NA, y_start = NA, 
                                   buffer_x = NA, buffer_y = NA, 
                                   hex_size = hex_size_vec[i],
                                   is_rm_lwd_hex = FALSE, 
                                   benchmark_to_rm_lwd_hex = NA, 
                                   col_start_2d = "tSNE", 
                                   col_start_highd = "x")
  
  centroid_df_training <- model_object$df_bin_centroids
  avg_df_training <- model_object$df_bin
  
  pred_emb_list <- predict_emb(test_data = clust_df, 
                                  df_bin_centroids = centroid_df_training, 
                                  df_bin = avg_df_training, type_NLDR = "tSNE")
  
  pred_df_training <- as.data.frame(do.call(cbind, pred_emb_list))
  
  eval_list <- gen_summary(test_data = clust_df, 
                                  prediction_df = pred_df_training, 
                                  df_bin = avg_df_training, col_start = "x")
  
  mse_df_gau <- mse_df_gau |>
    tibble::add_row(num_bins = num_bins_x * num_bins_y,
                    aic = eval_list$aic,
                    mse = eval_list$mse,
                    num_bins_x = num_bins_x,
                    num_bins_y = num_bins_y,
                    hex_size = hex_size_vec[i])
  
}
## If same total number of bins occurred only select ones with minimum error
### Obtain duplicate bins
dupli_bins <- mse_df_gau |> 
  dplyr::count(num_bins) |> 
  dplyr::filter(n > 1) |> 
  dplyr::pull(num_bins)
### Group split by duplicated bins
duplicate_df_list <- mse_df_gau |>
  dplyr::filter(num_bins %in% dupli_bins) |>
  dplyr::arrange(num_bins) |>
  dplyr::group_split(num_bins)
### Obtain one row from duplicates which have lowest error and hexsize
duplicate_df <- data.frame(matrix(nrow = 0, ncol = 0))
for (i in 1:length(duplicate_df_list)) {
  
  dd <- duplicate_df_list[[i]] |>
    dplyr::filter(mse == min(duplicate_df_list[[i]]$mse)) |>
    dplyr::filter(hex_size == min(duplicate_df_list[[i]]$hex_size))
  
  duplicate_df <- dplyr::bind_rows(duplicate_df, dd)
  
}
### Obtain the mse_df with not duplicated bins
not_dupli_df <- mse_df_gau |>
  dplyr::filter(!(num_bins %in% dupli_bins))
### Combine duplicated and not duplicated(corrected) bins dfs
mse_df_clust <- dplyr::bind_rows(not_dupli_df, duplicate_df) 
```

```{r}
mse_clust_plot <- ggplot(mse_df_clust, aes(x = num_bins,
                                       y = log(mse)
)) +
  geom_point() +
  geom_line() +
   geom_vline(xintercept = 588, linetype="solid",
                color = "red", size=0.8, alpha = 0.5) +
  theme_light() +
  theme(legend.position = "none", legend.title = element_blank(), plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title = element_text(size = 7),
        axis.text = element_text(size = 7)) +
  ylab("log(MSE)") +
  xlab("total number of bins")
```

```{r, fig.cap="Parameter tuning plots, where the best choice of parameter at a large drop in MSE. Here, these are at *total number of bins* = 180."}
mse_clust_plot
```

## Selecting parameter values for the model

<!--benchmark value to remove low density hexagons, long edges-->

## Fit the model

To perform the algorithm on the clustering data, we first scale the tSNE data. We then let *number of bins along the x-axis* be $21$, *number of bins along the y-axis* be $28$, and *hex_size* be 0.03; see [Selecting parameter values] for further discussion and guidance regarding selection of these choices. 

<!-- model with bin centroids-->
```{r}

## Decide by looking at MSE plot
num_bins_x_tsne_gau <- 21
num_bins_y_tsne_gau <- 28
hex_size_tsne_gau <- 0.03
## non-empty:198
hb_obj_tsne_gau <- hex_binning(data = tsne_gau_scaled, x = "tSNE1", 
                      y = "tSNE2", num_bins_x = num_bins_x_tsne_gau, 
                      num_bins_y = num_bins_y_tsne_gau, x_start = NA, y_start = NA, 
                      buffer_x = NA, buffer_y = NA, hex_size = hex_size_tsne_gau, col_start = "tSNE")
## Data set with all possible centroids in the hexagonal grid
all_centroids_df <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$centroids))
## Generate all coordinates of hexagons
hex_grid <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$hex_poly))
## To obtain the standardise counts within hexbins
counts_df <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$std_cts))
df_bin_centroids <- extract_hexbin_centroids(centroids_df = all_centroids_df, 
                                             counts_df = counts_df)
# ggplot(data = hex_grid, aes(x = x, y = y)) +
#   geom_polygon(fill = "white", color = "black", aes(group = hex_poly_id)) +
#   geom_point(data = all_centroids_df, aes(x = c_x, y = c_y), color = "red") +
#   coord_fixed()
hex_grid_with_counts <- dplyr::left_join(hex_grid, counts_df, by = c("hex_poly_id" = "hb_id"))
# ggplot(data = hex_grid_with_counts, aes(x = x, y = y)) +
#   geom_polygon(color = "black", aes(group = hex_poly_id, fill = std_counts)) +
#   geom_text(data = all_centroids_df, aes(x = c_x, y = c_y, label = hexID)) +
#   scale_fill_viridis_c(direction = -1, na.value = "#ffffff") +
#   coord_fixed()
tsne_data_with_hb_id_gau <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$data_hb_id))
  
model_object_tsne_gau <- fit_highd_model( training_data = clust_df, 
                                 nldr_df_with_id = tsne_gau_scaled, 
                                 x = "tSNE1", y = "tSNE2", 
                                 num_bins_x = num_bins_x_tsne_gau, 
                                 num_bins_y = num_bins_y_tsne_gau, 
                                 x_start = NA, y_start = NA, 
                                 buffer_x = NA, buffer_y = NA, 
                                 hex_size = hex_size_tsne_gau,
                                 is_rm_lwd_hex = FALSE, 
                                 benchmark_to_rm_lwd_hex = NA, 
                                 col_start_2d = "tSNE", 
                                 col_start_highd = "x")
df_bin_centroids_tsne_gau <- model_object_tsne_gau$df_bin_centroids
df_bin_tsne_gau <- model_object_tsne_gau$df_bin
## Triangulate bin centroids
tr1_object_tsne_gau <- tri_bin_centroids(df_bin_centroids_tsne_gau, x = "c_x", y = "c_y")
tr_from_to_df_tsne_gau <- gen_edges(tri_object = tr1_object_tsne_gau)
## Compute 2D distances
distance_tsne_gau <- cal_2d_dist(tr_coord_df = tr_from_to_df_tsne_gau, 
                             start_x = "x_from", start_y = "y_from", 
                             end_x = "x_to", end_y = "y_to", 
                             select_vars = c("from", "to", "distance"))
# distance_plot <- plot_dist(distance_tsne_gau) +
#   ylab(expression(d^{(2)})) +
#   theme(axis.text = element_text(size = 5),
#         axis.title = element_text(size = 12))
# 
# distance_plot
## To find the benchmark value
benchmark_tsne_gau <- find_lg_benchmark(distance_edges = distance_tsne_gau, distance_col = "distance")
# ggplot() +
# geom_trimesh(data = df_bin_centroids_tsne_gau, mapping = aes(x = c_x, y = c_y))
trimesh_removed_tsne_gau <- vis_rmlg_mesh(distance_edges = distance_tsne_gau, benchmark_value =
benchmark_tsne_gau, tr_coord_df = tr_from_to_df_tsne_gau, distance_col = "distance")
trimesh_removed_tsne_gau <- trimesh_removed_tsne_gau +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'a', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

trimesh_removed_tsne_gau

df_all_tsne_gau <- dplyr::bind_cols(clust_df |> dplyr::select(-ID), tsne_data_with_hb_id_gau)

### Define type column
df <- df_all_tsne_gau |>
  dplyr::select(tidyselect::starts_with("x")) |>
  dplyr::mutate(type = "data") ## original dataset

df_b <- df_bin_tsne_gau |>
  dplyr::filter(hb_id %in% df_bin_centroids_tsne_gau$hexID) |>
  dplyr::mutate(type = "model") ## Data with summarized mean
## Reorder the rows of df_b according to the hexID order in df_b_with_center_data
df_b <- df_b[match(df_bin_centroids_tsne_gau$hexID, df_b$hb_id),] |>
  dplyr::select(-hb_id)
df_exe <- dplyr::bind_rows(df_b, df)
## Set the maximum difference as the criteria
distance_df_small_edges <- distance_tsne_gau |>
  dplyr::filter(distance < benchmark_tsne_gau)
## Since erase brushing is considerd.
langevitour::langevitour(df_exe[1:(length(df_exe)-1)],
                         lineFrom = distance_df_small_edges$from,
                         lineTo = distance_df_small_edges$to,
                         group = df_exe$type, pointSize = append(rep(0, NROW(df_b)), rep(0.7, NROW(df))),
                         levelColors = c("#6a3d9a", "#33a02c"))

```


<!-- model with bin means-->
```{r}
## Decide by looking at MSE plot
num_bins_x_tsne_gau <- 21
num_bins_y_tsne_gau <- 28
hex_size_tsne_gau <- 0.03
## non-empty:198
hb_obj_tsne_gau <- hex_binning(data = tsne_gau_scaled, x = "tSNE1", 
                      y = "tSNE2", num_bins_x = num_bins_x_tsne_gau, 
                      num_bins_y = num_bins_y_tsne_gau, x_start = NA, y_start = NA, 
                      buffer_x = NA, buffer_y = NA, hex_size = hex_size_tsne_gau, col_start
= "tSNE")
## Data set with all possible centroids in the hexagonal grid
all_centroids_df <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$centroids))
## Generate all coordinates of hexagons
hex_grid <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$hex_poly))
## To obtain the standardise counts within hexbins
counts_df <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$std_cts))
df_bin_centroids <- extract_hexbin_centroids(centroids_df = all_centroids_df, 
                                             counts_df = counts_df)
# ggplot(data = hex_grid, aes(x = x, y = y)) +
#   geom_polygon(fill = "white", color = "black", aes(group = hex_poly_id)) +
#   geom_point(data = all_centroids_df, aes(x = c_x, y = c_y), color = "red") +
#   coord_fixed()
hex_grid_with_counts <- dplyr::left_join(hex_grid, counts_df, by = c("hex_poly_id" =
"hb_id"))
# ggplot(data = hex_grid_with_counts, aes(x = x, y = y)) +
#   geom_polygon(color = "black", aes(group = hex_poly_id, fill = std_counts)) +
#   geom_text(data = all_centroids_df, aes(x = c_x, y = c_y, label = hexID)) +
#   scale_fill_viridis_c(direction = -1, na.value = "#ffffff") +
#   coord_fixed()
tsne_data_with_hb_id_gau <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$data_hb_id))
  
model_object_tsne_gau <- fit_highd_model( training_data = clust_df, 
                                 nldr_df_with_id = tsne_gau_scaled, 
                                 x = "tSNE1", y = "tSNE2", 
                                 num_bins_x = num_bins_x_tsne_gau, 
                                 num_bins_y = num_bins_y_tsne_gau, 
                                 x_start = NA, y_start = NA, 
                                 buffer_x = NA, buffer_y = NA, 
                                 hex_size = hex_size_tsne_gau,
                                 is_bin_centroid = FALSE,
                                 is_rm_lwd_hex = FALSE, 
                                 benchmark_to_rm_lwd_hex = NA, 
                                 col_start_2d = "tSNE", 
                                 col_start_highd = "x")
df_bin_centroids_tsne_gau <- model_object_tsne_gau$df_bin_centroids
df_bin_tsne_gau <- model_object_tsne_gau$df_bin
## Triangulate bin centroids
tr1_object_tsne_gau <- tri_bin_centroids(df_bin_centroids_tsne_gau, x = "c_x", y = "c_y")
tr_from_to_df_tsne_gau <- gen_edges(tri_object = tr1_object_tsne_gau)
## Compute 2D distances
distance_tsne_gau <- cal_2d_dist(tr_coord_df = tr_from_to_df_tsne_gau, 
                             start_x = "x_from", start_y = "y_from", 
                             end_x = "x_to", end_y = "y_to", 
                             select_vars = c("from", "to", "distance"))
# distance_plot <- plot_dist(distance_tsne_gau) +
  # ylab(expression(d^{(2)})) +
  # theme(axis.text = element_text(size = 5),
        # axis.title = element_text(size = 12))

# distance_plot
## To find the benchmark value
benchmark_tsne_gau <- find_lg_benchmark(distance_edges = distance_tsne_gau, distance_col =
"distance")

benchmark_tsne_gau <- 0.17

# ggplot() +
# geom_trimesh(data = df_bin_centroids_tsne_gau, mapping = aes(x = c_x, y = c_y))
trimesh_removed_tsne_gau <- vis_rmlg_mesh(distance_edges = distance_tsne_gau, 
                                          benchmark_value = benchmark_tsne_gau, 
                                          tr_coord_df = tr_from_to_df_tsne_gau, distance_col = "distance")
trimesh_removed_tsne_gau <- trimesh_removed_tsne_gau +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'a', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size =
3)
trimesh_removed_tsne_gau
df_all_tsne_gau <- dplyr::bind_cols(clust_df |> dplyr::select(-ID),
tsne_data_with_hb_id_gau)
### Define type column
df <- df_all_tsne_gau |>
  dplyr::select(tidyselect::starts_with("x")) |>
  dplyr::mutate(type = "data") ## original dataset
df_b <- df_bin_tsne_gau |>
  dplyr::filter(hb_id %in% df_bin_centroids_tsne_gau$hexID) |>
  dplyr::mutate(type = "model") ## Data with summarized mean
## Reorder the rows of df_b according to the hexID order in df_b_with_center_data
df_b <- df_b[match(df_bin_centroids_tsne_gau$hexID, df_b$hb_id),] |>
  dplyr::select(-hb_id)
df_exe <- dplyr::bind_rows(df_b, df)
## Set the maximum difference as the criteria
distance_df_small_edges <- distance_tsne_gau |>
  dplyr::filter(distance < benchmark_tsne_gau)
## Since erase brushing is considerd.
langevitour::langevitour(df_exe[1:(length(df_exe)-1)],
                         lineFrom = distance_df_small_edges$from,
                         lineTo = distance_df_small_edges$to,
                         group = df_exe$type, pointSize = append(rep(0, NROW(df_b)),
rep(0.7, NROW(df))),
                         levelColors = c("#6a3d9a", "#33a02c"))
```


# Conclusion

This paper presents the R package `quollr` to develop a way to take the fitted model, as represented by the positions of points in 2D, and turn it into a high-dimensional wireframe to overlay on the data, viewing it with a tour.

The paper includes a clustering example to illustrate how `quollr` is useful to assess which NLDR technique and which hyperparameter choice gives the most accurate representation. In addition, how to select parameters for hexagonal binning and fitting model are explained.

Possible future improvements would be...<!--assess the preservation of local and glocal structure w.r.t 2D and high-D distance comparison--> 

This new tool provides an effective start point for automatically creating regular hexagons and help to evaluate which NLDR technique and which hyperparameter choice gives the most accurate representation of $p-D$ data.  

# Acknowledgements

This article is created using \CRANpkg{knitr} [@knitr] and \CRANpkg{rmarkdown} [@rmarkdown] in R with the `rjtools::rjournal_article` template. The source code for reproducing this paper can be found at: <https://github.com/JayaniLakshika/paper-quollr>.
