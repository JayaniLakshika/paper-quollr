---
title: "quollr: An R Package for Visalizing 2D Models in High Dimensional Space"
abstract: >
  An abstract of less than 150 words.
draft: true
author:  
  - name: Jayani P.G. Lakshika
    affiliation: Monash University
    address: Department of Econometrics and Business Statistics, VIC 3800 Australia
    url: https://jayanilakshika.netlify.app/
    orcid: 0000-0002-6265-6481
    email:  \email{jayani.piyadigamage@monash.edu}
  - name: Dianne Cook
    affiliation: Monash University
    address: Department of Econometrics and Business Statistics, VIC 3800 Australia
    url: http://www.dicook.org/
    email: dicook@monash.edu
    orcid: 0000-0002-3813-7155
  - name: Paul Harrison
    affiliation: Monash University
    address: MGBP, BDInstitute, VIC 3800 Australia
    email: paul.harrison@monash.edu
    orcid: 0000-0002-3980-268X
  - name: Michael Lydeamore
    affiliation: Monash University
    address: Department of Econometrics and Business Statistics, VIC 3800 Australia
    email: michael.lydeamore@monash.edu
    orcid: 0000-0001-6515-827X
  - name: Thiyanga S. Talagala
    affiliation: University of Sri Jayewardenepura
    address: Department of Statistics, Gangodawila, Nugegoda 10100 Sri Lanka
    url: https://thiyanga.netlify.app/
    email: ttalagala@sjp.ac.lk
    orcid: 0000-0002-0656-9789
type: package
preamble: >
  \usepackage{amsmath}
  \usepackage{array}
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
output: 
  rjtools::rjournal_article:
    self_contained: yes
    toc: no
bibliography: RJreferences.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE)

```

```{r load-libraries}
library(quollr)
library(tibble)
library(knitr)
library(kableExtra)
library(ggplot2)

set.seed(20230531)
```

# Introduction

# Methodology

## Usage

-   dependencies

-   basic example

### Datasets

The `quollr` package comes with several data sets that load with the package. These are described in Table `r knitr::asis_output(ifelse(knitr::is_html_output(), '\\@ref(tab:datasets-tb-html)', '\\@ref(tab:datasets-tb-pdf)'))`.

```{r, echo=FALSE}
datasets_tb <- tibble(dt = c("s_curve_noise",
                             "s_curve_noise_training", 
                             "s_curve_noise_test", 
                             "s_curve_noise_umap",
                             "s_curve_noise_umap_predict",
                             "s_curve_noise_umap_scaled"), 
                      text = c("Simulated 3D S-curve data with additional four noise dimensions.",
                               "Training data derived from S-curve data.", 
                               "Test data derived from S-curve data.", 
                               "UMAP 2D embedding data of S-curve data (n_neighbors: 15, min_dist: 0.1).",
                               "Predicted UMAP 2D embedding data of S-curve data",
                               "Scaled UMAP 2D embedding data of S-curve data"))
```

```{r datasets-tb-html, eval=is_html_output(), echo=FALSE}
datasets_tb |> 
  kable(caption = "quollr datasets", col.names = c("data", "explanation")) 
```

```{r datasets-tb-pdf, eval=is_latex_output(), echo=FALSE}
datasets_tb |>
  kable(caption = "quollr datasets", format="latex", col.names = c("data", "explanation"), booktabs = T)  |>
  column_spec(1, width = "4cm") |>
  column_spec(2, width = "8cm")
```

## Preprocessing

In the preprocessing stage, we aim to prepare our data to fit within the bounds required for regular hexagonal binning, ensuring effective visualization. To achieve this, we implement two key scaling steps. Firstly, we scale the first 2D embedding component to range between $0$ and $1$, ensuring that all data points fall within this normalized interval. Secondly, we scale the second 2D embedding component to range between $0$ and $y_{max}$. This adjustment helps maintain the necessary symmetry and spacing required for regular hexagons.

```{=tex}
\begin{equation}\label{eq:aspect_ratio}
ar = \frac{r_2}{r_1} \tag{1}
\end{equation}
```
```{=tex}
\begin{equation}\label{eq:y_max}
y_{max} = ceiling(\frac{ar}{hr}) * hr \tag{2}
\end{equation}
```
```{r}
scaled_data <- gen_scaled_data(data = s_curve_noise_umap, x = "UMAP1", 
                y = "UMAP2", hex_ratio = NA)
glimpse(scaled_data)
```

## Construct the 2D model

### Compute hexagonal bin configurations

## Construct the high-D model

## Model function

The `fit_highd_model()` function is used to generate both the 2D and high-D models.

```{r}
fit_highd_model(training_data = s_curve_noise_training, x = "UMAP1", y = "UMAP2",
nldr_df_with_id = s_curve_noise_umap_scaled, col_start_2d = "UMAP", col_start_highd = "x")
```

This function returns a list containing the estimated p-value as well as other useful statistics, including the empirical local correlations measured in the two time periods. See Table 4 for details concerning other arguments that may be passed to this function.

## Model summaries

### Predict 2D embeddings

There are some of NLDR techniques that don't give any functions for predictions. In that sense our methodology facilitates to compute 2D embedding with our workflow.

### Goodness of fit statistics

There are two Goodness of fit statistics were produced. MSE and AIC which interpret the model accuracy.

## Visualizations

We use static visualizations to understand the model constructed in 2D. On the other hand, dynamic visualization is used to see how the model looks in high-D space.

#### Static visualizations

Static visualizations main involves two types of results. One is the triangulation and the other is the long edge removal. Both types of visualizations provide ggplot objects.

-   Triangulation result: To visualize the results of triangulation, we input a dataset containing hexagonal bin centroid coordinates where 2D embedding data exists. `geom_trimesh()` is used to visualize this result.

-   Long edge removal: The long edge removal process involves identifying and removing long edges from the triangular mesh. Table shows the main arguments of the functions. We offer two functions for visualizing this process:

-   `colour_long_edges()`: This function colors the long edges within the triangular mesh by red.

-   `remove_long_edges()`: After identifying long edges, this function draws the triangular mesh without the long edges.

`r knitr::asis_output(ifelse(knitr::is_html_output(), '\\@ref(tab:lgvis-tb-html)', '\\@ref(tab:lgvis-tb-pdf)'))`

```{r, echo=FALSE}
lg_vis_tb <- tibble(dt = c(".data", 
                           "benchmark_value", 
                           "triangular_object", 
                           "distance_col"), 
                    text = c("The data frame containing the edge information.",
                             "The threshold value to determine long edges.", 
                             "The triangular object containing the mesh information.", 
                             "The column name in `.data` representing the distances."))
```

```{r lgvis-tb-html, eval=is_html_output(), echo=FALSE}
lg_vis_tb |> 
  kable(caption = "The main arguments for `vis_lg_mesh()` and `vis_rmlg_mesh()`", col.names = c("argument", "explanation")) 
```

```{r lgvis-tb-pdf, eval=is_latex_output(), echo=FALSE}
lg_vis_tb |>
  kable(caption = "The main arguments for `vis\\_lg\\_mesh()` and `vis\\_rmlg\\_mesh()`", format="latex", col.names = c("argument", "explanation"), booktabs = T)  |>
  column_spec(1, width = "4cm") |>
  column_spec(2, width = "8cm")
```

#### Dynamic visaulizations

The `show_langevitour()` function enables dynamic visualization of the 2D model alongside the high-dimensional (high-D) data in its original space. This visualization is facilitated by langevitour object, allowing users to interactively explore the relationship between the 2D embeddings and the underlying high-dimensional data. The main arguments are shown in Table `r knitr::asis_output(ifelse(knitr::is_html_output(), '\\@ref(tab:dyvis-tb-html)', '\\@ref(tab:dyvis-tb-pdf)'))`.

```{r, echo=FALSE}
dyn_vis_tb <- tibble(dt = c("df", 
                            "df_b", 
                            "df_b_with_center_data", 
                            "benchmark_value",
                            "distance_df",
                            "distance_col",
                            "use_default_benchmark_val",
                            "column_start_text"), 
                     text = c("A data frame containing the high-dimensional data.",
                              "A data frame containing the high-dimensional coordinates of bin centroids/means.",
                              "The dataset with hexbin centroids/ means.", 
                              "The benchmark value used to remove long edges (optional).", 
                              "The distance dataframe.",
                              "The name of the distance column.",
                              "Logical, indicating whether to use default benchmark value  to remove long edges(default is FALSE).",
                              "The text that begin the column name of the high-dimensional data."))
```

```{r dyvis-tb-html, eval=is_html_output(), echo=FALSE}
dyn_vis_tb |> 
  kable(caption = "The main arguments for `show_langevitour()`", col.names = c("argument", "explanation")) 
```

```{r dyvis-tb-pdf, eval=is_latex_output(), echo=FALSE}
dyn_vis_tb |>
  kable(caption = "The main arguments for `show\\_langevitour()`", format="latex", col.names = c("argument", "explanation"), booktabs = T)  |>
  column_spec(1, width = "4cm") |>
  column_spec(2, width = "8cm")
```

## Distance with bin means

```{r, echo=FALSE}

extract_hexbin_mean <- function(nldr_df_with_hex_id, counts_df) {

  ## To arrange the hexagon IDs
  counts_df <- counts_df |>
    dplyr::arrange(hb_id)

  ## To compute hexagonal bin means
  hex_mean_df <- nldr_df_with_hex_id |>
    dplyr::group_by(hb_id) |>
    dplyr::summarise(dplyr::across(tidyselect::everything(), mean)) |>
    dplyr::arrange(hb_id) |>
    dplyr::filter(hb_id %in% counts_df$hb_id) |>
    dplyr::mutate(std_counts = counts_df$std_counts)

  ## Rename columns
  names(hex_mean_df) <- c("hexID", "c_x", "c_y", "std_counts")

  return(hex_mean_df)
}
```

```{r}
bin_list <- calc_bins(data = s_curve_noise_umap_scaled, 
                      x = "UMAP1", y = "UMAP2", 
                      hex_size = NA, buffer_x = NA, 
                      buffer_y = NA)
num_bins_x <- bin_list$num_x
num_bins_y <- bin_list$num_y

hb_obj <- hex_binning(data = s_curve_noise_umap_scaled, 
                      x = "UMAP1", y = "UMAP2", 
                      num_bins_x = num_bins_x, num_bins_y = num_bins_y, 
                      x_start = NA, y_start = NA, 
                      buffer_x = NA, buffer_y = NA, 
                      hex_size = NA, col_start = "UMAP")


all_centroids_df <- as.data.frame(do.call(cbind, hb_obj$centroids))
counts_df <- as.data.frame(do.call(cbind, hb_obj$std_cts))
nldr_df_with_hex_id <- as.data.frame(do.call(cbind, hb_obj$data_hb_id))

## To obtain bin centroids
df_bin_centroids <- extract_hexbin_mean(nldr_df_with_hex_id = nldr_df_with_hex_id,
                                             counts_df = counts_df)

df_all <- dplyr::bind_cols(s_curve_noise_training |> dplyr::select(-ID), nldr_df_with_hex_id)

ggplot() + 
  geom_trimesh(data = df_bin_centroids, mapping = aes(x = c_x, y = c_y)) +
  coord_fixed()

tr1_object <- tri_bin_centroids(hex_df = df_bin_centroids, x = "c_x", y = "c_y")
tr_from_to_df <- gen_edges(tri_object = tr1_object)
distance_df <- cal_2d_dist(tr_coord_df = tr_from_to_df, 
                           start_x = "x_from", start_y = "y_from", 
                           end_x = "x_to", end_y = "y_to", 
                           select_vars = c("from", "to", "distance"))


## averaged high-D data
df_bin <- avg_highd_data(data = df_all, col_start = "x")

vis_lg_mesh(distance_edges = distance_df, benchmark_value = 1,
tr_coord_df = tr_from_to_df, distance_col = "distance")

vis_rmlg_mesh(distance_edges = distance_df, benchmark_value = 1,
tr_coord_df = tr_from_to_df, distance_col = "distance")

show_langevitour(df = df_all, df_b = df_bin, 
                 df_b_with_center_data = df_bin_centroids, 
                 benchmark_value = 1, distance = distance_df, 
                 distance_col = "distance", 
                 use_default_benchmark_val = FALSE, col_start = "x")
```

## Tests

All functions have tests written and implemented using the \CRANpkg{testthat} [@testthat] in R.

# Application

# Conclusion

# Acknowledgements

This article is created using \CRANpkg{knitr} [@knitr] and \CRANpkg{rmarkdown} [@rmarkdown] in R with the `rjtools::rjournal_article` template. The source code for reproducing this paper can be found at: <https://github.com/JayaniLakshika/paper-quollr>.
